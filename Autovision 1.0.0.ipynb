{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3008537e",
   "metadata": {},
   "source": [
    "# AUTOVISION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae126a0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:04:54.899526Z",
     "iopub.status.busy": "2023-03-24T05:04:54.899035Z",
     "iopub.status.idle": "2023-03-24T05:05:03.078684Z",
     "shell.execute_reply": "2023-03-24T05:05:03.077508Z"
    },
    "id": "lEzJXgjDf5y8",
    "papermill": {
     "duration": 8.198172,
     "end_time": "2023-03-24T05:05:03.081837",
     "exception": false,
     "start_time": "2023-03-24T05:04:54.883665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "# Tensorflow Libraries\n",
    "from tensorflow import keras\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Model\n",
    "#from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras import preprocessing\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING  - IF THIS DOESN'T PASS IT WONT RUN\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version: \", tf.__version__)\n",
    "\n",
    "# Check available devices\n",
    "print(\"Available devices:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(device)\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"Num GPUs Available: \", len(gpus))\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "\n",
    "# Check if TensorFlow is built with GPU support\n",
    "print(\"Is TensorFlow built with GPU support? \", tf.test.is_built_with_cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5c927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:03.112288Z",
     "iopub.status.busy": "2023-03-24T05:05:03.111030Z",
     "iopub.status.idle": "2023-03-24T05:05:05.810392Z",
     "shell.execute_reply": "2023-03-24T05:05:05.808384Z"
    },
    "papermill": {
     "duration": 2.720868,
     "end_time": "2023-03-24T05:05:05.816340",
     "exception": false,
     "start_time": "2023-03-24T05:05:03.095472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SEED TO REPRODUCE RESULTS\n",
    "def seed_everything(seed=42):\n",
    "    # Seed value for TensorFlow\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Seed value for NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Seed value for Python's random library\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Force TensorFlow to use single thread\n",
    "    # Multiple threads are a potential source of non-reproducible results.\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "\n",
    "    # Make sure that TensorFlow uses a deterministic operation wherever possible\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023d1bc",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:05.878356Z",
     "iopub.status.busy": "2023-03-24T05:05:05.877884Z",
     "iopub.status.idle": "2023-03-24T05:05:07.397474Z",
     "shell.execute_reply": "2023-03-24T05:05:07.396275Z"
    },
    "id": "F8ReVC2MiBRZ",
    "outputId": "c53e6082-d883-478d-d42f-887eb8399678",
    "papermill": {
     "duration": 1.537098,
     "end_time": "2023-03-24T05:05:07.400229",
     "exception": false,
     "start_time": "2023-03-24T05:05:05.863131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "\n",
    "# Import series of helper functions\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72d23d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:07.441166Z",
     "iopub.status.busy": "2023-03-24T05:05:07.440031Z",
     "iopub.status.idle": "2023-03-24T05:05:07.446182Z",
     "shell.execute_reply": "2023-03-24T05:05:07.444958Z"
    },
    "id": "8nD56d7Xxmc3",
    "papermill": {
     "duration": 0.019572,
     "end_time": "2023-03-24T05:05:07.448643",
     "exception": false,
     "start_time": "2023-03-24T05:05:07.429071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set batch size, image size, and enable mixed precision for faster training\n",
    "BATCH_SIZE = 16\n",
    "TARGET_SIZE = (224, 224)\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da32a03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:07.468820Z",
     "iopub.status.busy": "2023-03-24T05:05:07.468498Z",
     "iopub.status.idle": "2023-03-24T05:05:09.052630Z",
     "shell.execute_reply": "2023-03-24T05:05:09.050979Z"
    },
    "id": "5kXkjadNxsNI",
    "outputId": "478c212a-b21e-4e08-e472-9b101759173e",
    "papermill": {
     "duration": 1.596941,
     "end_time": "2023-03-24T05:05:09.055165",
     "exception": false,
     "start_time": "2023-03-24T05:05:07.458224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "dataset = r\"C:\\Users\\joshu\\OneDrive\\Desktop\\bunchatest\\DatasetCarmodel\"\n",
    "walk_through_dir(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a3cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:09.098823Z",
     "iopub.status.busy": "2023-03-24T05:05:09.098420Z",
     "iopub.status.idle": "2023-03-24T05:05:09.526539Z",
     "shell.execute_reply": "2023-03-24T05:05:09.525366Z"
    },
    "id": "s14XOEp01m_s",
    "papermill": {
     "duration": 0.443916,
     "end_time": "2023-03-24T05:05:09.529600",
     "exception": false,
     "start_time": "2023-03-24T05:05:09.085684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert image paths and labels into a DataFrame\n",
    "def convert_path_to_df(dataset):\n",
    "    image_dir = Path(dataset)  # Adjust path to include /train where images are stored\n",
    "    filepaths = list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "    image_df = pd.concat([filepaths, labels], axis=1)\n",
    "    return image_df\n",
    "image_df = convert_path_to_df(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be8703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:09.552383Z",
     "iopub.status.busy": "2023-03-24T05:05:09.551733Z",
     "iopub.status.idle": "2023-03-24T05:05:09.557689Z",
     "shell.execute_reply": "2023-03-24T05:05:09.556574Z"
    },
    "papermill": {
     "duration": 0.01993,
     "end_time": "2023-03-24T05:05:09.559967",
     "exception": false,
     "start_time": "2023-03-24T05:05:09.540037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Detect and collect corrupted .jpg images\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "# Adjust the path to your dataset location\n",
    "path = Path(r\"C:\\Users\\joshu\\OneDrive\\Desktop\\bunchatest\\DatasetCarmodel\").rglob(\"*.jpg\")\n",
    "corrupted_images = []\n",
    "for img_p in path:\n",
    "    try:\n",
    "        img = PIL.Image.open(img_p)\n",
    "    except PIL.UnidentifiedImageError:\n",
    "        print(f\"Corrupted image found: {img_p}\")\n",
    "        corrupted_images.append(img_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82891700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:09.581864Z",
     "iopub.status.busy": "2023-03-24T05:05:09.581527Z",
     "iopub.status.idle": "2023-03-24T05:05:09.956011Z",
     "shell.execute_reply": "2023-03-24T05:05:09.954916Z"
    },
    "id": "d3-uoP4n1oqK",
    "outputId": "4af0c4a5-c87d-42eb-aa1b-fe89f1fe8876",
    "papermill": {
     "duration": 0.388163,
     "end_time": "2023-03-24T05:05:09.958274",
     "exception": false,
     "start_time": "2023-03-24T05:05:09.570111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot label distribution as a bar chart\n",
    "\n",
    "label_counts = image_df['Label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values, alpha=0.8, palette='rocket')\n",
    "plt.title('Distribution of Labels in Image Dataset', fontsize=16)\n",
    "plt.xlabel('Label', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=45) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa167d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:10.004925Z",
     "iopub.status.busy": "2023-03-24T05:05:10.003770Z",
     "iopub.status.idle": "2023-03-24T05:05:11.475616Z",
     "shell.execute_reply": "2023-03-24T05:05:11.474245Z"
    },
    "id": "m4WJVJ7j1rU9",
    "outputId": "777f0f9a-e46c-4475-ca6a-97a4e6fb89a3",
    "papermill": {
     "duration": 1.504333,
     "end_time": "2023-03-24T05:05:11.495562",
     "exception": false,
     "start_time": "2023-03-24T05:05:09.991229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display 16 picture of the dataset with their labels\n",
    "random_index = np.random.randint(0, len(image_df), 16)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n",
    "    ax.set_title(image_df.Label[random_index[i]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd14e8",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:11.657854Z",
     "iopub.status.busy": "2023-03-24T05:05:11.657482Z",
     "iopub.status.idle": "2023-03-24T05:05:11.669034Z",
     "shell.execute_reply": "2023-03-24T05:05:11.668078Z"
    },
    "papermill": {
     "duration": 0.053602,
     "end_time": "2023-03-24T05:05:11.671364",
     "exception": false,
     "start_time": "2023-03-24T05:05:11.617762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate ELA image using OpenCV for model input\n",
    "def compute_ela_cv(path, quality):\n",
    "    temp_filename = 'temp_file_name.jpeg'\n",
    "    SCALE = 15\n",
    "    orig_img = cv2.imread(path)\n",
    "    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    cv2.imwrite(temp_filename, orig_img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
    "\n",
    "    # read compressed image\n",
    "    compressed_img = cv2.imread(temp_filename)\n",
    "\n",
    "    # get absolute difference between img1 and img2 and multiply by scale\n",
    "    diff = SCALE * cv2.absdiff(orig_img, compressed_img)\n",
    "    return diff\n",
    "\n",
    "# Generate ELA image using PIL for visualization\n",
    "def convert_to_ela_image(path, quality):\n",
    "    temp_filename = 'temp_file_name.jpeg'\n",
    "    ela_filename = 'temp_ela.png'\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "\n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "\n",
    "    scale = 255.0 / max_diff\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    return ela_image\n",
    "\n",
    "# Return a random image path from a given directory\n",
    "def random_sample(path, extension=\"jpg\"):  # Assuming your images are in .jpg format\n",
    "    items = list(Path(path).rglob(f'*.{extension}'))  # Using rglob to search subdirectories too\n",
    "    \n",
    "    if not items:  # Check if the list is empty\n",
    "        return None  # Return None or handle it as you see fit, e.g., raise an exception\n",
    "    \n",
    "    return random.choice(items).as_posix()  # Return the selected path as a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0fe61f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:11.749893Z",
     "iopub.status.busy": "2023-03-24T05:05:11.749493Z",
     "iopub.status.idle": "2023-03-24T05:05:13.587194Z",
     "shell.execute_reply": "2023-03-24T05:05:13.586048Z"
    },
    "papermill": {
     "duration": 1.901116,
     "end_time": "2023-03-24T05:05:13.610156",
     "exception": false,
     "start_time": "2023-03-24T05:05:11.709040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display a random saple from the dataset\n",
    "p = random_sample('C:/Users/joshu/OneDrive/Desktop/Car.com-Image-Scraper/efficientdataOfficial/train/W205')\n",
    "orig = cv2.imread(p)\n",
    "orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) / 255.0\n",
    "init_val = 100\n",
    "columns = 3\n",
    "rows = 3\n",
    "\n",
    "fig=plt.figure(figsize=(15, 10))\n",
    "for i in range(1, columns*rows +1):\n",
    "    quality=init_val - (i-1) * 8\n",
    "    img = compute_ela_cv(path=p, quality=quality)\n",
    "    if i == 1:\n",
    "        img = orig.copy()\n",
    "    ax = fig.add_subplot(rows, columns, i) \n",
    "    ax.title.set_text(f'q: {quality}')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befae5ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:13.893382Z",
     "iopub.status.busy": "2023-03-24T05:05:13.892894Z",
     "iopub.status.idle": "2023-03-24T05:05:13.902531Z",
     "shell.execute_reply": "2023-03-24T05:05:13.901563Z"
    },
    "papermill": {
     "duration": 0.083401,
     "end_time": "2023-03-24T05:05:13.904681",
     "exception": false,
     "start_time": "2023-03-24T05:05:13.821280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seperate data for training and testing\n",
    "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009ab47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:14.045639Z",
     "iopub.status.busy": "2023-03-24T05:05:14.045258Z",
     "iopub.status.idle": "2023-03-24T05:05:14.051159Z",
     "shell.execute_reply": "2023-03-24T05:05:14.049974Z"
    },
    "id": "3puUVDwl2Mcz",
    "papermill": {
     "duration": 0.079629,
     "end_time": "2023-03-24T05:05:14.053331",
     "exception": false,
     "start_time": "2023-03-24T05:05:13.973702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the ImageDataGenerator with augmentation only for training\n",
    "train_generator_aug = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    validation_split=0.2,  # 20% of training set will be used for validation\n",
    "    rotation_range=20,  # Augmentation parameters\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Use ImageDataGenerator without augmentation for validation and testing\n",
    "val_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    validation_split=0.2  # Same as above, split out validation data\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cb1ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:14.197474Z",
     "iopub.status.busy": "2023-03-24T05:05:14.197084Z",
     "iopub.status.idle": "2023-03-24T05:05:16.611179Z",
     "shell.execute_reply": "2023-03-24T05:05:16.609462Z"
    },
    "id": "CsftNShQ2PaK",
    "outputId": "ee3c99b5-3932-4187-f600-1e86cf334026",
    "papermill": {
     "duration": 2.489374,
     "end_time": "2023-03-24T05:05:16.613733",
     "exception": false,
     "start_time": "2023-03-24T05:05:14.124359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training data generator with augmentation\n",
    "train_images = train_generator_aug.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'  # This makes sure it's only using 80% of train_df\n",
    ")\n",
    "\n",
    "# Validation data generator without augmentation\n",
    "val_images = val_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,  # Still using the original train_df\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    subset='validation'  # This ensures 20% of train_df is used for validation\n",
    ")\n",
    "\n",
    "# Test data generator without augmentation\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,  # Test data remains completely independent\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59163e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:17.630797Z",
     "iopub.status.busy": "2023-03-24T05:05:17.629693Z",
     "iopub.status.idle": "2023-03-24T05:05:46.829434Z",
     "shell.execute_reply": "2023-03-24T05:05:46.828302Z"
    },
    "id": "z4VI_UxV2Wp2",
    "papermill": {
     "duration": 29.273407,
     "end_time": "2023-03-24T05:05:46.832408",
     "exception": false,
     "start_time": "2023-03-24T05:05:17.559001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.efficientnet_v2.EfficientNetV2L(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44f0ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:47.008054Z",
     "iopub.status.busy": "2023-03-24T05:05:47.006993Z",
     "iopub.status.idle": "2023-03-24T05:05:47.012829Z",
     "shell.execute_reply": "2023-03-24T05:05:47.011714Z"
    },
    "id": "1xn6j_La2Y2u",
    "papermill": {
     "duration": 0.095036,
     "end_time": "2023-03-24T05:05:47.015137",
     "exception": false,
     "start_time": "2023-03-24T05:05:46.920101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Callback for saving the entire model, not just the weights\n",
    "checkpoint_path = \"car_model_full_model_checkpoint_outofscope_.h5\"  # It's a good practice to use .h5 extension for full model saving\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      save_weights_only=False,  # Save the entire model\n",
    "                                      monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384e3e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:47.189031Z",
     "iopub.status.busy": "2023-03-24T05:05:47.187965Z",
     "iopub.status.idle": "2023-03-24T05:05:47.194533Z",
     "shell.execute_reply": "2023-03-24T05:05:47.193452Z"
    },
    "id": "YbP7g6Xh2abB",
    "papermill": {
     "duration": 0.09687,
     "end_time": "2023-03-24T05:05:47.197110",
     "exception": false,
     "start_time": "2023-03-24T05:05:47.100240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
    "                               patience = 10,\n",
    "                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3b841",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-03-24T05:05:47.547686Z",
     "iopub.status.busy": "2023-03-24T05:05:47.547017Z",
     "iopub.status.idle": "2023-03-24T05:59:53.790445Z",
     "shell.execute_reply": "2023-03-24T05:59:53.788941Z"
    },
    "id": "AkcAsl5H2tYl",
    "outputId": "173d8e87-7f30-401e-fe3b-077c21025b59",
    "papermill": {
     "duration": 3246.334282,
     "end_time": "2023-03-24T05:59:53.793017",
     "exception": false,
     "start_time": "2023-03-24T05:05:47.458735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = pretrained_model.input\n",
    "x = pretrained_model(inputs, training=False)\n",
    "\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "outputs = Dense(6, activation='softmax')(x)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Get unique classes\n",
    "classes = np.unique(train_df['Label'])\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=train_df['Label'])\n",
    "\n",
    "# Create dictionary mapping class names to weights\n",
    "name_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# Create dictionary mapping class indices to weights\n",
    "class_weight_dict = {train_images.class_indices[class_name]: weight \n",
    "                     for class_name, weight in name_weight_dict.items()}\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks for Training\n",
    "checkpoint_path = \"car_model_full_model_checkpoint_outofscope_.h5\"  # It's a good practice to use .h5 extension for full model saving\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      save_weights_only=False,  # Save the entire model\n",
    "                                      monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [\n",
    "    early_stopping,\n",
    "    create_tensorboard_callback(\"training_logs\", \"car_model_classification_v2\"),\n",
    "    checkpoint_callback,\n",
    "    reduce_lr\n",
    "]\n",
    "\n",
    "# Initial Training\n",
    "initial_epochs = 20\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=val_images,\n",
    "    validation_steps=len(val_images),\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=callbacks_list,\n",
    "    class_weight=class_weight_dict\n",
    ")\n",
    "\n",
    "# Fine-Tuning the Model\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "fine_tune_at = 300  # Adjust based on the model architecture\n",
    "\n",
    "for layer in pretrained_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue Training\n",
    "fine_tune_epochs = 300\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=val_images,\n",
    "    validation_steps=len(val_images),\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1]+ 1,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "# Save the entire model\n",
    "#model_save_path = \"car_model_classification_full_model\"\n",
    "#model.save(model_save_path)\n",
    "#print(f\"Full model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08109d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_save_path = \"car_model_classification_vidkoutofscope.h5\"\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7eb07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Path to your saved model\n",
    "model_path = \"car_model_full_model_checkpoint_outofscope_.h5\"\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c75ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T05:59:56.793082Z",
     "iopub.status.busy": "2023-03-24T05:59:56.792702Z",
     "iopub.status.idle": "2023-03-24T06:00:06.874100Z",
     "shell.execute_reply": "2023-03-24T06:00:06.873128Z"
    },
    "id": "CS-g90hJ340B",
    "outputId": "8b35403d-9dc0-4a65-b08e-ce223aef2bdb",
    "papermill": {
     "duration": 10.795818,
     "end_time": "2023-03-24T06:00:06.876539",
     "exception": false,
     "start_time": "2023-03-24T05:59:56.080721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c49a3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T06:00:09.554012Z",
     "iopub.status.busy": "2023-03-24T06:00:09.552886Z",
     "iopub.status.idle": "2023-03-24T06:00:10.043831Z",
     "shell.execute_reply": "2023-03-24T06:00:10.042855Z"
    },
    "id": "01SS6RVx38o7",
    "outputId": "f982ac64-9de4-4306-c917-1b7a1d0f6e06",
    "papermill": {
     "duration": 1.148539,
     "end_time": "2023-03-24T06:00:10.046058",
     "exception": false,
     "start_time": "2023-03-24T06:00:08.897519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy/loss curves\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e3097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T06:00:12.812243Z",
     "iopub.status.busy": "2023-03-24T06:00:12.811851Z",
     "iopub.status.idle": "2023-03-24T06:00:26.757662Z",
     "shell.execute_reply": "2023-03-24T06:00:26.756455Z"
    },
    "id": "KxAegJBB4HlW",
    "outputId": "c836256c-be8e-4346-b6c2-d4c39d030db4",
    "papermill": {
     "duration": 14.674538,
     "end_time": "2023-03-24T06:00:26.760660",
     "exception": false,
     "start_time": "2023-03-24T06:00:12.086122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "# Display the result\n",
    "print(f'The first 5 predictions: {pred[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4cff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T06:00:28.304801Z",
     "iopub.status.busy": "2023-03-24T06:00:28.304439Z",
     "iopub.status.idle": "2023-03-24T06:00:29.734873Z",
     "shell.execute_reply": "2023-03-24T06:00:29.733967Z"
    },
    "id": "pWO4e4wb4Iln",
    "outputId": "a58f3382-f991-43ac-e54f-6bd9a36dd25f",
    "papermill": {
     "duration": 2.344528,
     "end_time": "2023-03-24T06:00:29.762976",
     "exception": false,
     "start_time": "2023-03-24T06:00:27.418448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display 25 random pictures from the dataset with their labels\n",
    "random_index = np.random.randint(0, len(test_df) - 1, 15)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))\n",
    "    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n",
    "        color = \"green\"\n",
    "    else:\n",
    "        color = \"red\"\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852ef02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T06:00:33.274004Z",
     "iopub.status.busy": "2023-03-24T06:00:33.273633Z",
     "iopub.status.idle": "2023-03-24T06:00:33.295457Z",
     "shell.execute_reply": "2023-03-24T06:00:33.294325Z"
    },
    "id": "6ySAZoU74MlB",
    "outputId": "b4c6bf97-d4b1-4def-d1a8-bb79c9685504",
    "papermill": {
     "duration": 0.767517,
     "end_time": "2023-03-24T06:00:33.297691",
     "exception": false,
     "start_time": "2023-03-24T06:00:32.530174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94138da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T06:00:34.753465Z",
     "iopub.status.busy": "2023-03-24T06:00:34.753087Z",
     "iopub.status.idle": "2023-03-24T06:00:34.786030Z",
     "shell.execute_reply": "2023-03-24T06:00:34.784943Z"
    },
    "id": "bYWvkbXI4Ns2",
    "outputId": "7e04d8a2-3263-4a31-d469-70d8140cb167",
    "papermill": {
     "duration": 0.731015,
     "end_time": "2023-03-24T06:00:34.788490",
     "exception": false,
     "start_time": "2023-03-24T06:00:34.057475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_test, pred, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d5982b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-24T06:00:36.252476Z",
     "iopub.status.busy": "2023-03-24T06:00:36.252112Z",
     "iopub.status.idle": "2023-03-24T06:00:36.265090Z",
     "shell.execute_reply": "2023-03-24T06:00:36.264168Z"
    },
    "id": "QS8khAfS4Oy3",
    "papermill": {
     "duration": 0.776471,
     "end_time": "2023-03-24T06:00:36.267280",
     "exception": false,
     "start_time": "2023-03-24T06:00:35.490809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and display a labeled confusion matrix\n",
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(15, 7), text_size=10, norm=False, savefig=False): \n",
    "\n",
    "  # Create the confustion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
    "    n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
    "\n",
    "    # Plot the figure and make it pretty\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Are there a list of classes?\n",
    "    if classes:\n",
    "        labels = classes\n",
    "    else:\n",
    "        labels = np.arange(cm.shape[0])\n",
    "  \n",
    "    # Label the axes\n",
    "    ax.set(title=\"Confusion Matrix\",\n",
    "         xlabel=\"Predicted label\",\n",
    "         ylabel=\"True label\",\n",
    "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
    "         yticks=np.arange(n_classes), \n",
    "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
    "         yticklabels=labels)\n",
    "  \n",
    "    # Make x-axis labels appear on bottom\n",
    "    ax.xaxis.set_label_position(\"bottom\")\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n",
    "    plt.xticks(rotation=90, fontsize=text_size)\n",
    "    plt.yticks(fontsize=text_size)\n",
    "\n",
    "    # Set the threshold for different colors\n",
    "    threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "    # Plot the text on each cell\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if norm:\n",
    "            plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                size=text_size)\n",
    "        else:\n",
    "            plt.text(j, i, f\"{cm[i, j]}\",\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "              size=text_size)\n",
    "\n",
    "  # Save the figure to the current working directory\n",
    "    if savefig:\n",
    "        fig.savefig(\"confusion_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158d7b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T06:00:37.726457Z",
     "iopub.status.busy": "2023-03-24T06:00:37.726071Z",
     "iopub.status.idle": "2023-03-24T06:00:38.527799Z",
     "shell.execute_reply": "2023-03-24T06:00:38.526818Z"
    },
    "id": "vMsUQM6n4Pyx",
    "outputId": "3eb72904-123b-4e7b-d5b6-e3e339fab375",
    "papermill": {
     "duration": 1.562497,
     "end_time": "2023-03-24T06:00:38.530147",
     "exception": false,
     "start_time": "2023-03-24T06:00:36.967650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_confusion_matrix(y_test, pred, list(labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa77a0",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-24T06:00:41.652233Z",
     "iopub.status.busy": "2023-03-24T06:00:41.651840Z",
     "iopub.status.idle": "2023-03-24T06:00:41.667528Z",
     "shell.execute_reply": "2023-03-24T06:00:41.666598Z"
    },
    "papermill": {
     "duration": 0.716354,
     "end_time": "2023-03-24T06:00:41.669662",
     "exception": false,
     "start_time": "2023-03-24T06:00:40.953308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and prepare image as a model-ready array\n",
    "def get_img_array(img_path, size):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "# Create Grad-CAM heatmap to visualize model focus\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "# Overlay Grad-CAM heatmap on original image and save it\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "\n",
    "    \n",
    "    return cam_path\n",
    "    \n",
    "\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "decode_predictions = tf.keras.applications.efficientnet.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"top_conv\"\n",
    "img_size = (224,224, 3)\n",
    "\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to the image\n",
    "image_path = r\"c:\\Users\\joshu\\Downloads\\Screenshot 2024-09-20 220026.png\"\n",
    "\n",
    "# Define the target size (same as the input size of your model)\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Function to preprocess and predict a single image\n",
    "def classify_single_image(image_path, model, target_size):\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to create batch size of 1\n",
    "    img_array = tf.keras.applications.efficientnet_v2.preprocess_input(img_array)  # Preprocess as per EfficientNetV2\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    # Get the class labels from the model\n",
    "    labels = (train_images.class_indices)\n",
    "    labels = dict((v, k) for k, v in labels.items())  # Reverse the dictionary\n",
    "    \n",
    "    # Get the predicted classes and their corresponding confidence scores\n",
    "    predicted_classes = np.argsort(predictions[0])[::-1]  # Sort by confidence\n",
    "    predicted_confidences = np.sort(predictions[0])[::-1]  # Sorted confidences\n",
    "    \n",
    "    # Plot the image with its predicted labels and confidences\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Predictions and Confidences\")\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.show()\n",
    "    \n",
    "    # Print all predicted classes and their confidences\n",
    "    for i in range(len(predicted_classes)):\n",
    "        class_label = labels[predicted_classes[i]]\n",
    "        confidence = predicted_confidences[i] * 100\n",
    "        print(f\"Class: {class_label}, Confidence: {confidence:.2f}%\")\n",
    "\n",
    "    # Return the predicted classes and confidences as a dictionary\n",
    "    return {labels[predicted_classes[i]]: predicted_confidences[i] for i in range(len(predicted_classes))}\n",
    "\n",
    "# Run the classification on the single image\n",
    "predicted_labels_and_confidences = classify_single_image(image_path, model, target_size)\n",
    "print(predicted_labels_and_confidences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baacd9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract class labels from the training data generator\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v, k) for k, v in labels.items())  # Reverse the dictionary\n",
    "\n",
    "# Save labels to a JSON file for later use\n",
    "import json\n",
    "with open('class_labels.json', 'w') as f:\n",
    "    json.dump(labels, f)\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98adde0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T06:00:43.153672Z",
     "iopub.status.busy": "2023-03-24T06:00:43.153289Z",
     "iopub.status.idle": "2023-03-24T06:01:02.065178Z",
     "shell.execute_reply": "2023-03-24T06:01:02.064206Z"
    },
    "papermill": {
     "duration": 19.728647,
     "end_time": "2023-03-24T06:01:02.093345",
     "exception": false,
     "start_time": "2023-03-24T06:00:42.364698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show Grad-CAM heatmaps highlighting regions used for prediction\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img_path = test_df.Filepath.iloc[random_index[i]]\n",
    "    img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    cam_path = save_and_display_gradcam(img_path, heatmap)\n",
    "    ax.imshow(plt.imread(cam_path))\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3382.977388,
   "end_time": "2023-03-24T06:01:08.242382",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-24T05:04:45.264994",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
